{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHUlTKgQ4WL_",
        "outputId": "fafb1c6f-66df-4268-e7f8-562897814cab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.53-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.1.31)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.26.4)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.1.0)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.8.2)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.3.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.55.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.1)\n",
            "Downloading roboflow-1.1.53-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: filetype, python-dotenv, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.11.0.86\n",
            "    Uninstalling opencv-python-headless-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 python-dotenv-1.0.1 roboflow-1.1.53\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in My-First-Projectclas-1 to folder:: 100%|██████████| 311044/311044 [00:06<00:00, 47805.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to My-First-Projectclas-1 in folder:: 100%|██████████| 5430/5430 [00:02<00:00, 2646.12it/s]\n"
          ]
        }
      ],
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"qzy6wADsZuZjjvruIPY7\")\n",
        "project = rf.workspace(\"heithem-benmoussa-hvbkv\").project(\"my-first-projectclas\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"folder\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "maohKJ1v3-6g"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-t3Gb214AaP"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "import torch\n",
        "import os\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Paths\n",
        "data_dir = \"/content/My-First-Projectclas-1\"\n",
        "test_dir = os.path.join(data_dir, \"test\")\n",
        "train_dir = os.path.join(data_dir, \"train\")\n",
        "val_dir = os.path.join(data_dir, \"valid\")\n",
        "\n",
        "transform = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize(256),  \n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),  # Augmentation de couleurs\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalisation pour EfficientNet-B0\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(256),  \n",
        "        transforms.CenterCrop(224),  \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])  # Normalisation pour EfficientNet-B0\n",
        "    ]),\n",
        "    'test': transforms.Compose([  \n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j--PK1is4DL9"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_dataset = datasets.ImageFolder(train_dir, transform=transform['train'])\n",
        "val_dataset = datasets.ImageFolder(val_dir, transform=transform['val'])\n",
        "test_dataset = datasets.ImageFolder(test_dir, transform=transform['test'])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YF1MKKhf4GZH",
        "outputId": "b7d7531f-5a4c-4163-9f50-a9024c6e89f0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n"
          ]
        }
      ],
      "source": [
        "model = models.efficientnet_b0(pretrained=True)\n",
        "num_classes = len(train_dataset.classes)\n",
        "model.classifier[1] = nn.Linear(model.classifier[1].in_features, num_classes)\n",
        "model = model.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ab5KM7wX4Jiz"
      },
      "outputs": [],
      "source": [
        "\n",
        "class EarlyStopping:\n",
        "    def __init__(self, patience=10, verbose=False, delta=0, path='best_model.pth'):\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.delta = delta\n",
        "        self.path = path\n",
        "        self.counter = 0\n",
        "        self.best_score = None\n",
        "        self.early_stop = False\n",
        "        self.val_loss_min = float('inf')\n",
        "\n",
        "    def __call__(self, val_loss, model):\n",
        "        score = -val_loss\n",
        "        if self.best_score is None:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "        elif score < self.best_score + self.delta:\n",
        "            self.counter += 1\n",
        "            if self.verbose:\n",
        "                print(f\"EarlyStopping: Pas d'amélioration ({self.counter}/{self.patience})\")\n",
        "            if self.counter >= self.patience:\n",
        "                self.early_stop = True\n",
        "        else:\n",
        "            self.best_score = score\n",
        "            self.save_checkpoint(val_loss, model)\n",
        "            self.counter = 0\n",
        "\n",
        "    def save_checkpoint(self, val_loss, model):\n",
        "        if self.verbose:\n",
        "            print(f\"Validation Loss améliorée ({self.val_loss_min:.6f} → {val_loss:.6f}). Sauvegarde du modèle...\")\n",
        "        torch.save(model.state_dict(), self.path)\n",
        "        self.val_loss_min = val_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tayL-r4t4Lwf"
      },
      "outputs": [],
      "source": [
        "def calculate_metrics(y_true, y_pred, num_classes):\n",
        "    precision = precision_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    recall = recall_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=list(range(num_classes)))\n",
        "    return precision, recall, f1, cm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zlh8pnAC4PJL",
        "outputId": "e5d6e183-df51-48a1-ccce-a4df83e75467"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "Train Loss: 0.2094, Train Acc: 91.73%\n",
            "Val Loss: 0.6553, Val Acc: 79.17%\n",
            "Precision: 0.7960, Recall: 0.7949, F1 Score: 0.7916\n",
            "\n",
            "Validation Loss améliorée (inf → 0.655282). Sauvegarde du modèle...\n",
            "Epoch 2/50\n",
            "Train Loss: 0.1089, Train Acc: 97.09%\n",
            "Val Loss: 0.8010, Val Acc: 81.94%\n",
            "Precision: 0.8218, Recall: 0.8166, F1 Score: 0.8177\n",
            "\n",
            "EarlyStopping: Pas d'amélioration (1/10)\n",
            "Epoch 3/50\n",
            "Train Loss: 0.0688, Train Acc: 97.73%\n",
            "Val Loss: 0.6952, Val Acc: 77.78%\n",
            "Precision: 0.7810, Recall: 0.7740, F1 Score: 0.7750\n",
            "\n",
            "EarlyStopping: Pas d'amélioration (2/10)\n",
            "Epoch 4/50\n",
            "Train Loss: 0.0401, Train Acc: 99.14%\n",
            "Val Loss: 1.1746, Val Acc: 81.94%\n",
            "Precision: 0.8205, Recall: 0.8212, F1 Score: 0.8194\n",
            "\n",
            "EarlyStopping: Pas d'amélioration (3/10)\n",
            "Epoch 5/50\n",
            "Train Loss: 0.0938, Train Acc: 97.07%\n",
            "Val Loss: 0.4983, Val Acc: 79.17%\n",
            "Precision: 0.7975, Recall: 0.7872, F1 Score: 0.7884\n",
            "\n",
            "Validation Loss améliorée (0.655282 → 0.498339). Sauvegarde du modèle...\n",
            "Epoch 6/50\n",
            "Train Loss: 0.0468, Train Acc: 98.32%\n",
            "Val Loss: 0.7743, Val Acc: 83.33%\n",
            "Precision: 0.8359, Recall: 0.8359, F1 Score: 0.8333\n",
            "\n",
            "EarlyStopping: Pas d'amélioration (1/10)\n",
            "Epoch 7/50\n",
            "Train Loss: 0.0158, Train Acc: 99.54%\n",
            "Val Loss: 0.7855, Val Acc: 76.39%\n",
            "Precision: 0.7741, Recall: 0.7577, F1 Score: 0.7582\n",
            "\n",
            "EarlyStopping: Pas d'amélioration (2/10)\n",
            "Epoch 8/50\n",
            "Train Loss: 0.0133, Train Acc: 99.58%\n",
            "Val Loss: 0.6995, Val Acc: 84.72%\n",
            "Precision: 0.8483, Recall: 0.8491, F1 Score: 0.8472\n",
            "\n",
            "EarlyStopping: Pas d'amélioration (3/10)\n",
            "Epoch 9/50\n",
            "Train Loss: 0.0130, Train Acc: 99.87%\n",
            "Val Loss: 0.7533, Val Acc: 86.11%\n",
            "Precision: 0.8638, Recall: 0.8638, F1 Score: 0.8611\n",
            "\n",
            "EarlyStopping: Pas d'amélioration (4/10)\n",
            "Epoch 10/50\n",
            "Train Loss: 0.0967, Train Acc: 96.78%\n",
            "Val Loss: 0.7392, Val Acc: 83.33%\n",
            "Precision: 0.8328, Recall: 0.8328, F1 Score: 0.8328\n",
            "\n",
            "EarlyStopping: Pas d'amélioration (5/10)\n",
            "Epoch 11/50\n",
            "Train Loss: 0.0407, Train Acc: 99.70%\n",
            "Val Loss: 0.9415, Val Acc: 80.56%\n",
            "Precision: 0.8080, Recall: 0.8080, F1 Score: 0.8056\n",
            "\n",
            "EarlyStopping: Pas d'amélioration (6/10)\n",
            "Epoch 12/50\n",
            "Train Loss: 0.0489, Train Acc: 98.88%\n",
            "Val Loss: 0.6022, Val Acc: 81.94%\n",
            "Precision: 0.8264, Recall: 0.8150, F1 Score: 0.8166\n",
            "\n",
            "EarlyStopping: Pas d'amélioration (7/10)\n",
            "Epoch 13/50\n",
            "Train Loss: 0.0291, Train Acc: 98.86%\n",
            "Val Loss: 0.5511, Val Acc: 84.72%\n",
            "Precision: 0.8553, Recall: 0.8429, F1 Score: 0.8448\n",
            "\n",
            "EarlyStopping: Pas d'amélioration (8/10)\n"
          ]
        }
      ],
      "source": [
        "early_stopping = EarlyStopping(patience=10, verbose=True, path='best_model.pth')\n",
        "\n",
        "num_epochs = 50\n",
        "for epoch in range(num_epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_acc = 100. * correct / total\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_correct = 0\n",
        "    val_total = 0\n",
        "    all_labels = []\n",
        "    all_preds = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            val_total += labels.size(0)\n",
        "            val_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "    precision, recall, f1, cm = calculate_metrics(all_labels, all_preds, num_classes)\n",
        "    val_loss /= len(val_loader)\n",
        "    val_acc = 100. * val_correct / val_total\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "    print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\\n\")\n",
        "\n",
        "    # Early stopping check\n",
        "    early_stopping(val_loss, model)\n",
        "    if early_stopping.early_stop:\n",
        "        print(\"Arrêt anticipé !\")\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Co31ejaV6vui"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.load_state_dict(torch.load('best_model.pth'))\n",
        "print(\"Modèle chargé avec les meilleurs poids !\")\n",
        "\n",
        "model.eval()\n",
        "test_correct = 0\n",
        "test_total = 0\n",
        "all_test_labels = []\n",
        "all_test_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "\n",
        "        test_total += labels.size(0)\n",
        "        test_correct += predicted.eq(labels).sum().item()\n",
        "\n",
        "        all_test_labels.extend(labels.cpu().numpy())\n",
        "        all_test_preds.extend(predicted.cpu().numpy())\n",
        "\n",
        "precision_test, recall_test, f1_test, cm_test = calculate_metrics(all_test_labels, all_test_preds, num_classes)\n",
        "test_acc = 100. * test_correct / test_total\n",
        "\n",
        "print(f\"Test Accuracy: {test_acc:.2f}%\")\n",
        "print(f\"Test Precision: {precision_test:.4f}, Recall: {recall_test:.4f}, F1 Score: {f1_test:.4f}\")\n",
        "print(f\"Confusion Matrix:\\n{cm_test}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwdo2ro361fG",
        "outputId": "6b296dde-3448-41e9-ff62-f821d582d7c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Métriques sauvegardées dans metrics.json\n"
          ]
        }
      ],
      "source": [
        "metrics = {\n",
        "    \"Validation\": {\n",
        "        \"Loss\": val_loss,\n",
        "        \"Accuracy\": val_acc,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1 Score\": f1\n",
        "    },\n",
        "    \"Test\": {\n",
        "        \"Accuracy\": test_acc,\n",
        "        \"Precision\": precision_test,\n",
        "        \"Recall\": recall_test,\n",
        "        \"F1 Score\": f1_test,\n",
        "        \"Confusion Matrix\": cm_test.tolist()\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(\"metrics.json\", \"w\") as f:\n",
        "    json.dump(metrics, f, indent=4)\n",
        "print(\"Métriques sauvegardées dans metrics.json\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
